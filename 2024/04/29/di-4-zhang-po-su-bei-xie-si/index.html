<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>第4章 朴素贝叶斯 | StudyinCAU</title><meta name="author" content="小楼一夜听春雨 &amp; Rico"><meta name="copyright" content="小楼一夜听春雨 &amp; Rico"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="第4章 朴素贝叶斯 引言 在众多机器学习分类算法中，本篇我们提到的朴素贝叶斯模型，和其他绝大多数分类算法都不同，也是很重要的模型之一。 在众多机器学习的分类算法中，朴素贝叶斯模型以其独特的方法和重要性，与其他算法显著不同。相对于KNN、逻辑回归、决策树等判别方法，这些算法直接学习输入特征X与输出Y之间的直接关系（决策函数 \(Y&#x3D;f(x)\) 或者条件分布 \(P(Y \mid X)\)​ ），朴">
<meta property="og:type" content="article">
<meta property="og:title" content="第4章 朴素贝叶斯">
<meta property="og:url" content="https://studyincau.github.io/2024/04/29/di-4-zhang-po-su-bei-xie-si/index.html">
<meta property="og:site_name" content="StudyinCAU">
<meta property="og:description" content="第4章 朴素贝叶斯 引言 在众多机器学习分类算法中，本篇我们提到的朴素贝叶斯模型，和其他绝大多数分类算法都不同，也是很重要的模型之一。 在众多机器学习的分类算法中，朴素贝叶斯模型以其独特的方法和重要性，与其他算法显著不同。相对于KNN、逻辑回归、决策树等判别方法，这些算法直接学习输入特征X与输出Y之间的直接关系（决策函数 \(Y&#x3D;f(x)\) 或者条件分布 \(P(Y \mid X)\)​ ），朴">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://studyincau.github.io/images/ML.jpg">
<meta property="article:published_time" content="2024-04-29T14:19:53.000Z">
<meta property="article:modified_time" content="2024-05-26T15:23:01.000Z">
<meta property="article:author" content="小楼一夜听春雨 &amp; Rico">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://studyincau.github.io/images/ML.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://studyincau.github.io/2024/04/29/di-4-zhang-po-su-bei-xie-si/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '第4章 朴素贝叶斯',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-05-26 23:23:01'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.1.1">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">119</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">212</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">56</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/../images/ML.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="StudyinCAU"><span class="site-name">StudyinCAU</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">第4章 朴素贝叶斯</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-04-29T14:19:53.000Z" title="发表于 2024-04-29 22:19:53">2024-04-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-05-26T15:23:01.000Z" title="更新于 2024-05-26 23:23:01">2024-05-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">机器学习方法</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>12分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="第4章 朴素贝叶斯"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="第4章-朴素贝叶斯">第4章 朴素贝叶斯</h1>
<h2 id="引言">引言</h2>
<p>在众多机器学习分类算法中，本篇我们提到的朴素贝叶斯模型，和其他绝大多数分类算法都不同，也是很重要的模型之一。</p>
<p>在众多机器学习的分类算法中，朴素贝叶斯模型以其独特的方法和重要性，与其他算法显著不同。相对于KNN、逻辑回归、决策树等判别方法，这些算法直接学习输入特征X与输出Y之间的直接关系（决策函数
<span class="math inline">\(Y=f(x)\)</span> 或者条件分布 <span class="math inline">\(P(Y \mid X)\)</span>​
），朴素贝叶斯模型则采用了生成方法。它直接找出特征输出Y和特征
X的联合分布 <span class="math inline">\(P(X, Y)\)</span> ，进而通过
<span class="math display">\[
P(Y \mid X)=\frac{P(X, Y)}{P(X)}
\]</span></p>
<p>计算得出结果判定。</p>
<h2 id="朴素贝叶斯算法原理">朴素贝叶斯算法原理</h2>
<h3 id="贝叶斯定理">贝叶斯定理</h3>
<p>贝叶斯理论是以18世纪的一位神学家托马斯.贝叶斯(Thomas
Bayes)命名。通常，事件A在事件B (发生) 的条件下的概率，与事件B在事件A
(发生)
的条件下的概率是不一样的。然而，这两者是有确定的关系的，贝叶斯定理就是这种关系的陈述。
<span class="math display">\[
P(A \mid B)=\frac{P(B \mid A) P(A)}{P(B)}
\]</span></p>
<ul>
<li>条件概率：就是事件 <span class="math inline">\(A\)</span>
在另外一个事件 <span class="math inline">\(B\)</span>
已经发生条件下的发生概率。条件概率表示为 <span class="math inline">\(P(A
\mid B)\)</span> ，即在 <span class="math inline">\(B\)</span>
发生的条件下 <span class="math inline">\(A\)</span> 发生的概率。</li>
<li>联合概率：表示两个事件共同发生（数学概念上的交集）的概率。 <span class="math inline">\(A\)</span> 与 <span class="math inline">\(B\)</span>
的联合概率表示为联合概率。联合概率表示为 <span class="math inline">\(P(A
B)\)</span> <span class="math display">\[
P(A B)=P(A \mid B) P(B)=P(B \mid A) P(A) \text {, 若 } A B \text {
相互独立, 则} P(A B)=P(A) P(B)
\]</span></li>
<li>全概率公式: <span class="math inline">\(\displaystyle P(X)=\sum_k
P\left(X \mid Y=Y_k\right) P\left(Y_k\right)\)</span>， 其中 <span class="math inline">\(\displaystyle  \sum_k
P\left(Y_k\right)=1\)</span></li>
</ul>
<h3 id="朴素贝叶斯">朴素贝叶斯</h3>
<p>朴素贝叶斯方法是<strong>基于贝叶斯定理</strong>和特征条件独立假设的<strong>分类方法</strong>。</p>
<p>这是一个较强的假设。由于这一假设，模型包含的条件概率的数量大为减少，朴素贝叶斯法的学习与预测大为简化。因而朴素贝叶斯法高效，且易于实现。其缺点是分类的性能不一定很高。</p>
<p>对于给定的训练数据集：</p>
<ol type="1">
<li>首先基于特征条件独立假设学习输入 / 输出的联合概率分布</li>
<li>然后基于此模型，对给定的输入 <span class="math inline">\(x\)</span>
，利用贝叶斯定理求出后验概率最大的输出 <span class="math inline">\(y\)</span> :</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
P\left(X=x \mid Y=c_k\right) &amp; =P\left(X^{(1)}=x^{(1)}, \cdots,
X^{(n)}=x^{(n)} \mid Y=c_k\right) \\
&amp; =\prod_{j=1}^n P\left(X^{(j)}=x^{(j)} \mid Y=c_k\right)
\end{aligned}\tag{1}
\]</span></p>
<p><strong>原理</strong></p>
<p>朴素贝叶斯方法属于生成模型的范畴。在给定输入 <span class="math inline">\(x\)</span>
的情况下，这种方法通过已学习的模型计算后验概率分布 <span class="math inline">\(P(Y=c_k \mid X=x)\)</span>
。它选择后验概率最高的类别 $c_k $ 作为输入 $x $
的预测分类。其中<strong>后验概率的计算</strong>基于贝叶斯定理进行<br>
<span class="math display">\[
\begin{aligned}
P\left(Y=c_k \mid X=x\right) &amp;= \frac{P\left(X=x \mid Y=c_k\right)
P\left(Y=c_k\right)}{\displaystyle \sum_k P\left(X=x \mid Y=c_k\right)
P\left(Y=c_k\right)}
\end{aligned}\tag{2}
\]</span> 将式<span class="math inline">\((1)\)</span>代入式<span class="math inline">\((2)\)</span>，有 <span class="math display">\[
P\left(Y=c_k \mid X=x\right)=\frac{\displaystyle P\left(Y=c_k\right)
\prod_j P\left(X^{(j)}=x^{(j)} \mid Y=c_k\right)}{\displaystyle \sum_{k}
P\left(Y=c_k\right) \prod_{j} P\left(X^{(j)}=x^{(j)} \mid
Y=c_k\right)},k=1,2, \cdots, K\tag{3}
\]</span> 这是朴素贝叶斯法分类的基本公式。于是, 朴素贝叶斯分类器可表示为
<span class="math display">\[
y=f(x)=\arg \max _{c_k} \frac{\displaystyle P\left(Y=c_k\right) \prod_j
P\left(X^{(j)}=x^{(j)} \mid Y=c_k\right)}{\displaystyle \sum_k
P\left(Y=c_k\right) \prod_j P\left(X^{(j)}=x^{(j)} \mid
Y=c_k\right)}\tag{4}
\]</span> 注意到, 在式 <span class="math inline">\((4)\)</span>
中分母对所有 <span class="math inline">\(c_k\)</span> 都是相同的，所以
<span class="math display">\[
y=\arg \max _{c_k} P\left(Y=c_k\right) \prod_j P\left(X^{(j)}=x^{(j)}
\mid Y=c_k\right)\tag{5}
\]</span></p>
<h3 id="后验概率最大化的含义">后验概率最大化的含义</h3>
<p>朴素贝叶斯法将实例分到后验概率最大的类中,
这等价于期望风险最小化。假设选择 0-1 损失函数: <span class="math display">\[
L(Y, f(X))=\left\{\begin{array}{rr}
1, &amp; Y \neq f(X) \\
0, &amp; Y=f(X)
\end{array}\right.\tag{6}
\]</span></p>
<p>式中 <span class="math inline">\(f(X)\)</span>
是分类决策函数。这时，期望风险函数为 <span class="math display">\[
R_{\exp }(f)=E[L(Y, f(X))]\tag{7}
\]</span> 期望是对联合分布 <span class="math inline">\(P(X, Y)\)</span>
取的。由此取条件期望 <span class="math display">\[
R_{\exp }(f)=E_X \sum_{k=1}^K\left[L\left(c_k, f(X)\right)\right]
P\left(c_k \mid X\right)\tag{8}
\]</span></p>
<p>为了使期望风险最小化, 只需对 <span class="math inline">\(X=x\)</span>
逐个极小化, 由此得到: <span class="math display">\[
\begin{aligned}
f(x) &amp; =\arg \min _{y \in \mathcal{Y}} \sum_{k=1}^K L\left(c_k,
y\right) P\left(c_k \mid X=x\right) \\
&amp; =\arg \min _{y \in \mathcal{Y}} \sum_{k=1}^K P\left(y \neq c_k
\mid X=x\right) \\\\
&amp; =\arg \min _{y \in \mathcal{Y}}\left(1-P\left(y=c_k \mid
X=x\right)\right) \\\\
&amp; =\arg \max _{y \in \mathcal{Y}} P\left(y=c_k \mid X=x\right)
\end{aligned}\tag{9}
\]</span></p>
<p>这样一来, 根据期望风险最小化准则就得到了后验概率最大化准则: <span class="math display">\[
f(x)=\arg \max _{c_k} P\left(c_k \mid X=x\right)\tag{10}
\]</span></p>
<p>即朴素贝叶斯法所采用的原理。</p>
<h3 id="极大似然估计">极大似然估计</h3>
<p>在朴素贝叶斯法中，学习意味着估计 <span class="math inline">\(P\left(Y=c_k\right)\)</span> 和 <span class="math inline">\(P\left(X^{(j)}=x^{(j)} \mid Y=c_k\right)\)</span>
。可以应用极大似然估计法估计相应的概率。先验概率 <span class="math inline">\(P\left(Y=c_k\right)\)</span> 的极大似然估计是
<span class="math display">\[
P\left(Y=c_k\right)=\frac{\displaystyle \sum_{i=1}^N
I\left(y_i=c_k\right)}{N}, \quad k=1,2, \cdots, K
\tag{11}
\]</span></p>
<p>设第 <span class="math inline">\(j\)</span> 个特征 <span class="math inline">\(x^{(j)}\)</span> 可能取值的集合为 <span class="math inline">\(\left\{a_{j 1}, a_{j 2}, \cdots, a_{j
S_j}\right\}\)</span>，条件概率 <span class="math inline">\(P\left(X^{(j)}=a_{j l} \mid
Y=c_k\right)\)</span>的极大似然估计是 <span class="math display">\[
\begin{aligned}
&amp; P\left(X^{(j)}=a_{j l} \mid Y=c_k\right)=\frac{\displaystyle
\sum_{i=1}^N I\left(x_i^{(j)}=a_{j l}, y_i=c_k\right)}{\displaystyle
\sum_{i=1}^N I\left(y_i=c_k\right)}, \\
&amp; j=1,2, \cdots, n, \quad l=1,2, \cdots, S_j, \quad k=1,2, \cdots, K
\end{aligned}\tag{12}
\]</span></p>
<p>式中， <span class="math inline">\(x_i^{(j)}\)</span> 是第 <span class="math inline">\(i\)</span> 个样本的第 <span class="math inline">\(j\)</span> 个特征； <span class="math inline">\(a_{j l}\)</span> 是第 <span class="math inline">\(j\)</span> 个特征可能取的第 <span class="math inline">\(l\)</span> 个值； <span class="math inline">\(I\)</span> 为指示函数。</p>
<p><strong>创建训练集和测试集</strong></p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> math</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># data</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_data</span>():</span><br><span class="line">    iris = load_iris()</span><br><span class="line">    df = pd.DataFrame(iris.data, columns=iris.feature_names)</span><br><span class="line">    df[<span class="string">'label'</span>] = iris.target</span><br><span class="line">    df.columns = [</span><br><span class="line">        <span class="string">'sepal length'</span>, <span class="string">'sepal width'</span>, <span class="string">'petal length'</span>, <span class="string">'petal width'</span>, <span class="string">'label'</span></span><br><span class="line">    ]</span><br><span class="line">    data = np.array(df.iloc[:<span class="number">100</span>, :])</span><br><span class="line">    <span class="comment"># print(data)</span></span><br><span class="line">    <span class="keyword">return</span> data[:, :-<span class="number">1</span>], data[:, -<span class="number">1</span>]</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">X, y = create_data()</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>)</span><br><span class="line">X_test[<span class="number">0</span>], y_test[<span class="number">0</span>]</span><br></pre></td></tr></tbody></table></figure>
<p><code>Output[ ]</code></p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">(array([6.6, 2.9, 4.6, 1.3]), 1.0)</span><br></pre></td></tr></tbody></table></figure>
<ul>
<li><h3 id="高斯模型">高斯模型</h3>
<p><strong>GaussianNB 高斯朴素贝叶斯</strong>
特征的可能性被假设为高斯概率密度函数: <span class="math display">\[
P\left(x_i \mid y_k\right)=\frac{1}{\sqrt{2 \pi \sigma_{y k}^2}} \exp
\left(-\frac{\left(x_i-\mu_{y k}\right)^2}{2 \sigma_{y
k}^2}\right)\tag{13}
\]</span></p>
<p>数学期望： <span class="math inline">\(\mu\)</span> 方差: <span class="math inline">\(\sigma^2=\frac{\sum(X-\mu)^2}{N}\)</span></p></li>
</ul>
<h4 id="实现一个朴素贝叶斯分类器"><strong>实现一个朴素贝叶斯分类器</strong></h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NaiveBayes</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.model = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数学期望</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mean</span>(<span class="params">X</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(X) / <span class="built_in">float</span>(<span class="built_in">len</span>(X))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 标准差（方差）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">stdev</span>(<span class="params">self, X</span>):</span><br><span class="line">        avg = self.mean(X)</span><br><span class="line">        <span class="keyword">return</span> math.sqrt(<span class="built_in">sum</span>([<span class="built_in">pow</span>(x - avg, <span class="number">2</span>) <span class="keyword">for</span> x <span class="keyword">in</span> X]) / <span class="built_in">float</span>(<span class="built_in">len</span>(X)))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 概率密度函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">gaussian_probability</span>(<span class="params">self, x, mean, stdev</span>):</span><br><span class="line">        exponent = math.exp(-(math.<span class="built_in">pow</span>(x - mean, <span class="number">2</span>) /</span><br><span class="line">                              (<span class="number">2</span> * math.<span class="built_in">pow</span>(stdev, <span class="number">2</span>))))</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">1</span> / (math.sqrt(<span class="number">2</span> * math.pi) * stdev)) * exponent</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 处理X_train</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">summarize</span>(<span class="params">self, train_data</span>):</span><br><span class="line">        summaries = [(self.mean(i), self.stdev(i)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">zip</span>(*train_data)]</span><br><span class="line">        <span class="keyword">return</span> summaries</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分类别求出数学期望和标准差</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y</span>):</span><br><span class="line">        labels = <span class="built_in">list</span>(<span class="built_in">set</span>(y))</span><br><span class="line">        data = {label: [] <span class="keyword">for</span> label <span class="keyword">in</span> labels}</span><br><span class="line">        <span class="keyword">for</span> f, label <span class="keyword">in</span> <span class="built_in">zip</span>(X, y):</span><br><span class="line">            data[label].append(f)</span><br><span class="line">        self.model = {</span><br><span class="line">            label: self.summarize(value)</span><br><span class="line">            <span class="keyword">for</span> label, value <span class="keyword">in</span> data.items()</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'gaussianNB train done!'</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算概率</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">calculate_probabilities</span>(<span class="params">self, input_data</span>):</span><br><span class="line">        <span class="comment"># summaries:{0.0: [(5.0, 0.37),(3.42, 0.40)], 1.0: [(5.8, 0.449),(2.7, 0.27)]}</span></span><br><span class="line">        <span class="comment"># input_data:[1.1, 2.2]</span></span><br><span class="line">        probabilities = {}</span><br><span class="line">        <span class="keyword">for</span> label, value <span class="keyword">in</span> self.model.items():</span><br><span class="line">            probabilities[label] = <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(value)):</span><br><span class="line">                mean, stdev = value[i]</span><br><span class="line">                probabilities[label] *= self.gaussian_probability(</span><br><span class="line">                    input_data[i], mean, stdev)</span><br><span class="line">        <span class="keyword">return</span> probabilities</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 类别</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X_test</span>):</span><br><span class="line">        <span class="comment"># {0.0: 2.9680340789325763e-27, 1.0: 3.5749783019849535e-26}</span></span><br><span class="line">        label = <span class="built_in">sorted</span>(</span><br><span class="line">            self.calculate_probabilities(X_test).items(),</span><br><span class="line">            key=<span class="keyword">lambda</span> x: x[-<span class="number">1</span>])[-<span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">self, X_test, y_test</span>):</span><br><span class="line">        right = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> <span class="built_in">zip</span>(X_test, y_test):</span><br><span class="line">            label = self.predict(X)</span><br><span class="line">            <span class="keyword">if</span> label == y:</span><br><span class="line">                right += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> right / <span class="built_in">float</span>(<span class="built_in">len</span>(X_test))</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">model = NaiveBayes()</span><br><span class="line">model.fit(X_train, y_train)</span><br></pre></td></tr></tbody></table></figure>
<p><code>Output[ ]</code></p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">'gaussianNB train done!'</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(model.predict([<span class="number">4.4</span>,  <span class="number">3.2</span>,  <span class="number">1.3</span>,  <span class="number">0.2</span>]))</span><br></pre></td></tr></tbody></table></figure>
<p><code>Output[ ]</code></p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">0.0</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">model.score(X_test, y_test)</span><br></pre></td></tr></tbody></table></figure>
<p><code>Output[ ]</code></p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">1.0</span><br></pre></td></tr></tbody></table></figure>
<h4 id="scikit-learn实例"><strong>scikit-learn实例</strong></h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line">clf = GaussianNB()</span><br><span class="line">clf.fit(X_train, y_train)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">clf.score(X_test, y_test)</span><br></pre></td></tr></tbody></table></figure>
<p><code>Output[ ]</code></p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">1.0</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">clf.predict([[<span class="number">4.4</span>,  <span class="number">3.2</span>,  <span class="number">1.3</span>,  <span class="number">0.2</span>]])</span><br></pre></td></tr></tbody></table></figure>
<p><code>Output[ ]</code></p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">array([0.])</span><br></pre></td></tr></tbody></table></figure>
<p><strong>而scikit-learn中的伯努利模型和多项式模型</strong></p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> BernoulliNB, MultinomialNB <span class="comment"># 伯努利模型和多项式模型</span></span><br></pre></td></tr></tbody></table></figure>
<hr>
<h2 id="第4章朴素贝叶斯法-习题">第4章朴素贝叶斯法-习题</h2>
<h3 id="用极大似然估计法推出朴素贝叶斯法中的概率估计公式11及公式-12">1.用极大似然估计法推出朴素贝叶斯法中的概率估计公式<span class="math inline">\((11)\)</span>及公式 <span class="math inline">\((12)\)</span>。</h3>
<p><strong>解答：</strong><br>
<strong>第1步：</strong>证明公式<span class="math inline">\((11)\)</span>：<span class="math inline">\(\displaystyle P(Y=c_k) = \frac{\displaystyle
\sum_{i=1}^N I(y_i=c_k)}{N}\)</span></p>
<p>由于朴素贝叶斯法假设<span class="math inline">\(Y\)</span>是定义在输出空间<span class="math inline">\(\mathcal{Y}\)</span>上的随机变量，因此可以定义<span class="math inline">\(P(Y=c_k)\)</span>概率为<span class="math inline">\(p\)</span>。</p>
<p>令<span class="math inline">\(\displaystyle
m=\sum_{i=1}^NI(y_i=c_k)\)</span>，得出似然函数： <span class="math display">\[
L(p)=f_D(y_1,y_2,\cdots,y_n|\theta)=\binom{N}{m}p^m(1-p)^{(N-m)}
\]</span> 使用微分求极值，两边同时对<span class="math inline">\(p\)</span>求微分： <span class="math display">\[
\begin{aligned}
0 &amp;=
\binom{N}{m}\left[mp^{(m-1)}(1-p)^{(N-m)}-(N-m)p^m(1-p)^{(N-m-1)}\right]
\\
&amp; = \binom{N}{m}\left[p^{(m-1)}(1-p)^{(N-m-1)}(m-Np)\right]
\end{aligned}
\]</span> 可求解得到： <span class="math display">\[
\displaystyle p=0,p=1,p=\frac{m}{N}
\]</span> 显然 <span class="math display">\[
\begin{aligned}
\displaystyle P(Y=c_k)&amp;=p
=\frac{m}{N}
=\frac{\displaystyle \sum_{i=1}^N I(y_i=c_k)}{N}
\end{aligned}
\]</span> 公式<span class="math inline">\((11)\)</span>得证。</p>
<hr>
<p><strong>第2步：</strong>证明公式<span class="math inline">\((11)\)</span>： <span class="math display">\[
\displaystyle P(X^{(j)}=a_{jl}|Y=c_k) = \frac{\displaystyle \sum_{i=1}^N
I(x_i^{(j)}=a_{jl},y_i=c_k)}{\displaystyle \sum_{i=1}^N I(y_i=c_k)}
\]</span> 令 <span class="math display">\[
P(X^{(j)}=a_{jl}|Y=c_k)=p
\]</span></p>
<p><span class="math display">\[
\displaystyle m=\sum_{i=1}^N I(y_i=c_k), q=\sum_{i=1}^N
I(x_i^{(j)}=a_{jl},y_i=c_k)
\]</span></p>
<p>得出似然函数： <span class="math display">\[
L(p)=\binom{m}{q}p^q(i-p)^{m-q}
\]</span> 使用微分求极值，两边同时对<span class="math inline">\(p\)</span>求微分： <span class="math display">\[
\begin{aligned}
0 &amp;=
\binom{m}{q}\left[qp^{(q-1)}(1-p)^{(m-q)}-(m-q)p^q(1-p)^{(m-q-1)}\right]
\\
&amp; = \binom{m}{q}\left[p^{(q-1)}(1-p)^{(m-q-1)}(q-mp)\right]
\end{aligned}
\]</span> 可求解得到 <span class="math display">\[
\displaystyle p=0,p=1,p=\frac{q}{m}
\]</span></p>
<p>显然 <span class="math display">\[
\displaystyle P(X^{(j)}=a_{jl}|Y=c_k)=p=\frac{q}{m}=\frac{\displaystyle
\sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k)}{\displaystyle \sum_{i=1}^N
I(y_i=c_k)}
\]</span> 公式<span class="math inline">\((12)\)</span>得证。</p>
<hr>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://studyincau.github.io">小楼一夜听春雨 &amp; Rico</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://studyincau.github.io/2024/04/29/di-4-zhang-po-su-bei-xie-si/">https://studyincau.github.io/2024/04/29/di-4-zhang-po-su-bei-xie-si/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://studyincau.github.io" target="_blank">StudyinCAU</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div><div class="post_share"><div class="social-share" data-image="/../images/ML.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/05/03/ren-gong-zhi-neng-kuang-jia/" title="人工智能框架思维导图"><img class="cover" src="/../images/ML.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">人工智能框架思维导图</div></div></a></div><div class="next-post pull-right"><a href="/2024/04/29/di-03-zhang-k-jin-lin-fa/" title="第3章 k近邻法"><img class="cover" src="/../images/ML.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">第3章 k近邻法</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/04/28/di-01-zhang-tong-ji-xue-xi-fang-fa-gai-lun/" title="第1章 统计学习方法概论"><img class="cover" src="/../images/ML.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-28</div><div class="title">第1章 统计学习方法概论</div></div></a></div><div><a href="/2024/04/28/di-02-zhang-gan-zhi-ji/" title="第2章 感知机"><img class="cover" src="/../images/ML.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-28</div><div class="title">第2章 感知机</div></div></a></div><div><a href="/2024/04/29/di-03-zhang-k-jin-lin-fa/" title="第3章 k近邻法"><img class="cover" src="/../images/ML.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-29</div><div class="title">第3章 k近邻法</div></div></a></div><div><a href="/2024/03/24/mit-deep-learning-bootcamp-phillip-isola/" title="MIT Deep Learning Bootcamp_ Phillip Isola"><img class="cover" src="/../images/background1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-24</div><div class="title">MIT Deep Learning Bootcamp_ Phillip Isola</div></div></a></div><div><a href="/2024/03/18/shen-du-xue-xi-ji-chu-zhi-shi/" title="深度学习基础知识"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-18</div><div class="title">深度学习基础知识</div></div></a></div><div><a href="/2024/05/28/ji-qi-xue-xi-gai-lun/" title="机器学习概论"><img class="cover" src="/../images/ML.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-28</div><div class="title">机器学习概论</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">小楼一夜听春雨 &amp; Rico</div><div class="author-info__description">Study</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">119</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">212</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">56</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/StudyinCAU"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/StudyinCAU" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:3187248635@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">这是一个分享学习笔记(资料)的网站，欢迎一起学习、交流。如果你有好的文章也想分享，可以发邮箱(邮箱在公告上方~)[若出现渲染问题或加载过慢，推荐用谷歌或Edge浏览器打开]</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="toc-text">第4章 朴素贝叶斯</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80"><span class="toc-text">引言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="toc-text">朴素贝叶斯算法原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86"><span class="toc-text">贝叶斯定理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="toc-text">朴素贝叶斯</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87%E6%9C%80%E5%A4%A7%E5%8C%96%E7%9A%84%E5%90%AB%E4%B9%89"><span class="toc-text">后验概率最大化的含义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1"><span class="toc-text">极大似然估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B"><span class="toc-text">高斯模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-text">实现一个朴素贝叶斯分类器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#scikit-learn%E5%AE%9E%E4%BE%8B"><span class="toc-text">scikit-learn实例</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC4%E7%AB%A0%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95-%E4%B9%A0%E9%A2%98"><span class="toc-text">第4章朴素贝叶斯法-习题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%E6%B3%95%E6%8E%A8%E5%87%BA%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95%E4%B8%AD%E7%9A%84%E6%A6%82%E7%8E%87%E4%BC%B0%E8%AE%A1%E5%85%AC%E5%BC%8F11%E5%8F%8A%E5%85%AC%E5%BC%8F-12"><span class="toc-text">1.用极大似然估计法推出朴素贝叶斯法中的概率估计公式\((11)\)及公式 \((12)\)。</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/07/14/my-notes/" title="Datawhale AI夏令营 电力需求预测赛"><img src="/../images/xunfei.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Datawhale AI夏令营 电力需求预测赛"/></a><div class="content"><a class="title" href="/2024/07/14/my-notes/" title="Datawhale AI夏令营 电力需求预测赛">Datawhale AI夏令营 电力需求预测赛</a><time datetime="2024-07-14T12:19:31.000Z" title="发表于 2024-07-14 20:19:31">2024-07-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/06/27/shu-li-tong-ji-6-5-qu-jian-gu-ji/" title="第五节 区间估计"><img src="/../images/background46.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="第五节 区间估计"/></a><div class="content"><a class="title" href="/2024/06/27/shu-li-tong-ji-6-5-qu-jian-gu-ji/" title="第五节 区间估计">第五节 区间估计</a><time datetime="2024-06-27T08:15:37.000Z" title="发表于 2024-06-27 16:15:37">2024-06-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/06/25/pylearn/" title="Python基本语法"><img src="/../images/python3.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python基本语法"/></a><div class="content"><a class="title" href="/2024/06/25/pylearn/" title="Python基本语法">Python基本语法</a><time datetime="2024-06-25T09:13:15.000Z" title="发表于 2024-06-25 17:13:15">2024-06-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/06/01/hua-tu/" title="Python可视化"><img src="/../images/seaborn.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python可视化"/></a><div class="content"><a class="title" href="/2024/06/01/hua-tu/" title="Python可视化">Python可视化</a><time datetime="2024-05-31T18:33:05.000Z" title="发表于 2024-06-01 02:33:05">2024-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/05/28/ji-qi-xue-xi-gai-lun/" title="机器学习概论"><img src="/../images/ML.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="机器学习概论"/></a><div class="content"><a class="title" href="/2024/05/28/ji-qi-xue-xi-gai-lun/" title="机器学习概论">机器学习概论</a><time datetime="2024-05-28T15:07:22.000Z" title="发表于 2024-05-28 23:07:22">2024-05-28</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2024 By 小楼一夜听春雨 & Rico</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(() => {
  const initValine = () => {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'xFi1vMHzzqw1qFKQbyK4WtAo-gzGzoHsz',
      appKey: 'hGyKCk4AFAr9aPSCHioyb0hH',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  const loadValine = async () => {
    if (typeof Valine === 'function') initValine()
    else {
      await getScript('https://cdn.jsdelivr.net/npm/valine@1.5.1/dist/Valine.min.js')
      initValine()
    }
  }

  if ('Valine' === 'Valine' || !true) {
    if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script></div><link rel="stylesheet" href="/css/title.css"><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>